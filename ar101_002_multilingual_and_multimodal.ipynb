{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae790cfc-cff7-48e6-bc3b-295769cc7a07",
   "metadata": {},
   "source": [
    "# Advanced Retrieval 101 Multilingual and Multimodal Search with LlamaIndex\n",
    "\n",
    "https://qdrant.tech/documentation/multimodal-search/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cc50e-ec6c-460a-9bb0-5224fee6aedb",
   "metadata": {},
   "source": [
    "## Vectorize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2d1d91-c62e-4d05-948b-50d11466d16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "size must contain 'shortest_edge' and 'longest_edge' keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbedding\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mHuggingFaceEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllamaindex/vdr-2b-multi-v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"mps\" for mac, \"cuda\" for nvidia GPUs, \"cpu\"\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m documents = [\n\u001b[32m     11\u001b[39m     {\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcaption\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAn image about plane emergency safety\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     },\n\u001b[32m     31\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/llama_index/embeddings/huggingface/base.py:155\u001b[39m, in \u001b[36mHuggingFaceEmbedding.__init__\u001b[39m\u001b[34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager, parallel_process, target_devices, **model_kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe `model_name` argument must be provided.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_instruction\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_query_instruct_for_model_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_instruction\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_text_instruct_for_model_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_length:\n\u001b[32m    169\u001b[39m     model.max_seq_length = max_length\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:308\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    299\u001b[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + model_name_or_path\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[32m    302\u001b[39m     model_name_or_path,\n\u001b[32m    303\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    307\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    320\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    321\u001b[39m         model_name_or_path,\n\u001b[32m    322\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    329\u001b[39m         config_kwargs=config_kwargs,\n\u001b[32m    330\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1739\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1736\u001b[39m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[32m   1737\u001b[39m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     module = module_class.load(model_name_or_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/llamaindex/vdr-2b-multi-v1/2c4e54c8db4071cc61fc3c62f4490124e40c37db/custom_st.py:65\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, processor_name_or_path, max_pixels, min_pixels, dimension, max_seq_length, model_args, processor_args, tokenizer_args, config_args, cache_dir, backend, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mself\u001b[39m.model = Qwen2VLForConditionalGeneration.from_pretrained(\n\u001b[32m     59\u001b[39m     model_name_or_path,\n\u001b[32m     60\u001b[39m     cache_dir=cache_dir,\n\u001b[32m     61\u001b[39m     **model_kwargs\n\u001b[32m     62\u001b[39m ).eval()\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Initialize processor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28mself\u001b[39m.processor = \u001b[43mAutoProcessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessor_name_or_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprocessor_kwargs\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Set padding sides\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.model.padding_side = \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py:345\u001b[39m, in \u001b[36mAutoProcessor.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class.from_pretrained(\n\u001b[32m    342\u001b[39m         pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n\u001b[32m    343\u001b[39m     )\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocessor_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m PROCESSOR_MAPPING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1070\u001b[39m, in \u001b[36mProcessorMixin.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1068\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m] = token\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m args = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m processor_dict, kwargs = \u001b[38;5;28mcls\u001b[39m.get_processor_dict(pretrained_model_name_or_path, **kwargs)\n\u001b[32m   1072\u001b[39m processor_dict.update({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m processor_dict.keys()})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1134\u001b[39m, in \u001b[36mProcessorMixin._get_arguments_from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1132\u001b[39m         attribute_class = \u001b[38;5;28mcls\u001b[39m.get_possibly_dynamic_module(class_name)\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m     args.append(\u001b[43mattribute_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:557\u001b[39m, in \u001b[36mAutoImageProcessor.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image_processor_class.from_dict(config_dict, **kwargs)\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m image_processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_processor_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# Last try: we use the IMAGE_PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m IMAGE_PROCESSOR_MAPPING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:423\u001b[39m, in \u001b[36mImageProcessingMixin.from_dict\u001b[39m\u001b[34m(cls, image_processor_dict, **kwargs)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcrop_size\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcrop_size\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m image_processor_dict:\n\u001b[32m    421\u001b[39m     image_processor_dict[\u001b[33m\"\u001b[39m\u001b[33mcrop_size\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcrop_size\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m image_processor = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mimage_processor_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# Update image_processor with kwargs if needed\u001b[39;00m\n\u001b[32m    426\u001b[39m to_remove = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-fastembed/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl.py:144\u001b[39m, in \u001b[36mQwen2VLImageProcessor.__init__\u001b[39m\u001b[34m(self, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, do_convert_rgb, min_pixels, max_pixels, patch_size, temporal_patch_size, merge_size, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mshortest_edge\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m size \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlongest_edge\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m size):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msize must contain \u001b[39m\u001b[33m'\u001b[39m\u001b[33mshortest_edge\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlongest_edge\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keys.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     size = {\u001b[33m\"\u001b[39m\u001b[33mshortest_edge\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m56\u001b[39m * \u001b[32m56\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlongest_edge\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m28\u001b[39m * \u001b[32m28\u001b[39m * \u001b[32m1280\u001b[39m}\n",
      "\u001b[31mValueError\u001b[39m: size must contain 'shortest_edge' and 'longest_edge' keys."
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "model = HuggingFaceEmbedding(\n",
    "    model_name=\"llamaindex/vdr-2b-multi-v1\",\n",
    "    device=\"mps\",  # \"mps\" for mac, \"cuda\" for nvidia GPUs, \"cpu\"\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"caption\": \"An image about plane emergency safety\",\n",
    "        \"image\": \"images/place_emergency.jpg\",\n",
    "    },\n",
    "    {\n",
    "        \"caption\": \"An image about airplane components.\",\n",
    "        \"image\": \"images/airplane_parts.png\",\n",
    "    },\n",
    "    {\n",
    "        \"caption\": \"An image about COVID safety restrictions.\",\n",
    "        \"image\": \"images/coronavirus-safety.jpg\",\n",
    "    },\n",
    "    {\n",
    "        \"caption\": \"A confidential image about UFO sightings\",\n",
    "        \"image\": \"images/ufo_sightings.jpeg\",\n",
    "    },\n",
    "    {\n",
    "        \"caption\": \"An image about US stock market news\",\n",
    "        \"image\": \"images/us_stock_market_news.png\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a5912-d9c6-443b-92f1-acb677b3d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = model.get_text_embedding_batch([doc[\"caption\"] for doc in documents])\n",
    "image_embeddings = model.get_image_embedding_batch([doc[\"image\"] for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ba252-0229-45d0-bd5c-ecc7ae8a01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "if not client.collection_exists(\"llama-multi\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"llama-multi\",\n",
    "        vectors_config={\n",
    "            \"image\": models.VectorParams(\n",
    "                size=len(image_embeddings[0]), distance=models.Distance.COSINE\n",
    "            ),\n",
    "            \"text\": models.VectorParams(\n",
    "                size=len(text_embeddings[0]), distance=models.Distance.COSINE\n",
    "            ),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7fc4f8-2d17-4f26-8bfd-738a600418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=\"llama-multi\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            vector={\n",
    "                \"text\": text_embeddings[idx],\n",
    "                \"image\": image_embeddings[idx],\n",
    "            },\n",
    "            payload=doc,\n",
    "        )\n",
    "        for idx, doc in enumerate(documents)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ce9ca-0113-4d4f-ba3c-6ce37b84c7f1",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de009a2-e381-4b03-81d0-2d1cdc1e9c10",
   "metadata": {},
   "source": [
    "### Text-to-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf639f-9037-45dc-a6dc-3b013592a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "find_image = model.get_query_embedding(\"Bullish on US Equity\")\n",
    "\n",
    "Image.open(\n",
    "    client.query_points(\n",
    "        collection_name=\"llama-multi\",\n",
    "        query=find_image,\n",
    "        using=\"image\",\n",
    "        with_payload=[\"image\"],\n",
    "        limit=1,\n",
    "    )\n",
    "    .points[0]\n",
    "    .payload[\"image\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7febf7-a200-4666-b298-fd23c843a98f",
   "metadata": {},
   "source": [
    "### Multilingual Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952b5a2-1418-4bab-9dea-67cfe09bb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\n",
    "    client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        # German: Tell me about the mysterious object\n",
    "        query=model.get_query_embedding(\"erzähl mir von dem mysteriösen Objekt\"),\n",
    "        using=\"image\",\n",
    "        with_payload=[\"image\"],\n",
    "        limit=1,\n",
    "    )\n",
    "    .points[0]\n",
    "    .payload[\"image\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
