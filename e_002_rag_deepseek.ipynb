{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8f1ca4-5fa9-4d51-802b-66a84376b92b",
   "metadata": {},
   "source": [
    "# Essentials: 5 Minute RAG with Qdrant and DeepSeek\n",
    "\n",
    "https://qdrant.tech/documentation/rag-deepseek/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14b4ed6-2050-438f-ba3f-12925d838395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f41f675-f172-4878-900f-a9d8aa753906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8703ac373720496b804a998945f641ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15d3676ac2f41f4b78b2c46ed99af7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6847071b9ce048769f9c3b23f810bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efff0377c5f41dc8e4e8ea404598f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b58f990e5d4161ac5231b5eb201d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21189bffeed414ea4a5c4b8e25152f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['60aabd4c0a9a4323a4d613a068c36e33',\n",
       " 'b8f3fbe4a4734476a25d6e07ce6f962c',\n",
       " '2d5bec3dd79e415187c34dcd23332281',\n",
       " '5f30e4332ed745e3921756ba3b6db0f3',\n",
       " 'e714a72590ee451588adce8f05debdf5',\n",
       " '1e2833b9c65a4101918c4b8fd80d311d',\n",
       " '908559de554048d4bdd6342e6dfc96f6',\n",
       " '7034b9f4df0f4e1bbd849de14b2a8601']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\":memory:\")\n",
    "client.set_model(\"BAAI/bge-base-en-v1.5\")\n",
    "client.add(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    # The collection is automatically created if it doesn't exist.\n",
    "    documents=[\n",
    "        \"Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\",\n",
    "        \"Docker helps developers build, share, and run applications anywhere â€” without tedious environment configuration or management.\",\n",
    "        \"PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\",\n",
    "        \"MySQL is an open-source relational database management system (RDBMS). A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database.\",\n",
    "        \"NGINX is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\",\n",
    "        \"FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\",\n",
    "        \"SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\",\n",
    "        \"The cron command-line utility is a job scheduler on Unix-like operating systems. Users who set up and maintain software environments use cron to schedule jobs (commands or shell scripts), also known as cron jobs, to run periodically at fixed times, dates, or intervals.\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ecf8fbe-f965-4257-b9cb-b667f1ffcb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "What tools should I need to use to build a web service using vector embeddings for search?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0ec80c-95a5-480e-8e68-99706436a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import ChatResponse, chat\n",
    "\n",
    "\n",
    "def query_deepseek(prompt) -> str:\n",
    "    response: ChatResponse = chat(\n",
    "        model=\"deepseek-r1:8b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61bad8c2-db10-4cf1-badb-8ed492157ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I'm trying to figure out what tools I need to build a web service that uses vector embeddings for search. I remember hearing about vector embeddings in the context of machine learning and natural language processing, but I'm not exactly sure how they work or how they can be applied to building a search function.\\n\\nFirst, I think I need some way to generate these vectors from text inputs. Maybe there are libraries that can create embeddings based on the input data. The assistant mentioned TensorFlow and PyTorch as deep learning frameworks. Since I have some Python experience, maybe I should start with those. But what exactly do they offer in terms of vector embeddings?\\n\\nI remember there's something called Word2Vec which creates word vectors. So perhaps using a pre-trained model or implementing one could help generate these embeddings for each query. Also, FastText comes up often as an alternative to Word2 Vec, and it can handle subwords, which might be useful if my application deals with partial matches.\\n\\nNext, I need a way to store these vectors so they can be searched efficiently. The assistant talked about FAISS, which is a library for similarity search. That sounds like exactly what I need because it's optimized for fast approximate searches. But I think FAISS is more for similarity-based searches rather than exact matches. How do I handle when the query isn't an exact match but close to one?\\n\\nThen there's Milvus, another vector search engine that can handle large datasets. It seems like both FAISS and Milvus are good options, but maybe depending on the scale of my application. If it's small, FAISS might be easier to set up. But if I expect a lot of queries or a large corpus, Milvus could be better.\\n\\nAfter that, building an API is essential so other services can send requests and receive results. The assistant mentioned Flask for microservices and FastAPI as an alternative. I've heard FastAPI is faster and more modern, so maybe it's worth learning that instead of Flask. Also, using ASGI instead of WSGI could make the server more efficient.\\n\\nFor the search logic itself, implementing a function that takes user input, generates embeddings, and then searches through the stored vectors makes sense. But how do I handle ranking? Do I just get the most similar vector, or do I have to implement some way to score them?\\n\\nOn the database side, I need something that can store vectors efficiently and allow for fast lookups. Maybe using a NoSQL database like MongoDB or PostgreSQL with specific data types that can handle vectors. But how do I structure the documents so that they're easily searchable? Should each document have its vector stored as well as metadata?\\n\\nTesting will be important too, especially since embeddings can sometimes have accuracy issues. The assistant mentioned sentence embedding models, which might be necessary if I'm dealing with phrases instead of individual words.\\n\\nThe user experience is another consideration. How do users input their search queries? Do they type in text, submit a form, and get results based on that? Also, how to handle cases where the query doesn't exactly match anything but has similar concepts.\\n\\nCost is something to think about too. If I'm using cloud-based services like AWS or Google Cloud with their managed solutions, it might be more accessible than setting up everything from scratch, especially if I don't have a lot of computational resources on my own servers.\\n\\nI also wonder about the efficiency of generating embeddings. For each query, is there a limit to how many vectors can be processed quickly? If the application is going to handle a lot of queries, I might need to optimize the embedding generation process, maybe using pre-processing steps or caching results.\\n\\nAnother thing is handling multiple languages. If my service needs to support different languages, I'll have to decide on monolingual or multilingual embeddings. Word2Vec can be trained for specific languages, while BERT embeddings are multilingual. But training BERT might require more resources and expertise.\\n\\nIn terms of deployment, containerization with Docker could help package the application into a container that can run anywhere. Caching strategies might also improve performance by storing frequently accessed results or embeddings to reduce processing time on subsequent queries.\\n\\nDocumentation is important too. Users will need clear instructions on how to use the service effectively. Also, error handling and rate limiting should be considered to prevent abuse or overuse of the service.\\n\\nI'm a bit overwhelmed with all these aspects, but breaking it down into steps might help. First, choose the vector embedding method, then pick the search engine, set up the API, store data appropriately, implement the query logic, handle results ranking, and ensure efficient processing. Testing each component as I go would make it manageable.\\n\\nI should probably start by installing one of the deep learning libraries like TensorFlow or PyTorch and try a simple embedding model. Then experiment with FAISS or Milvus to see how they integrate with my data. Once that's working, move on to building the API with FastAPI and set up a basic search endpoint.\\n\\nI'm also thinking about data preprocessing. What format do I need my text data in? Should I use TF-IDF for term frequency, or is embedding generation sufficient? Maybe a combination of both could improve the search results by using TF-IDF for ranking and embeddings for similarity.\\n\\nOverall, it's a complex task but manageable with the right tools and step-by-step approach. I'll need to stay updated on the latest libraries and maybe join some forums or communities where people discuss vector search applications to troubleshoot any issues.\\n</think>\\n\\nTo build a web service using vector embeddings for search, follow this structured approach:\\n\\n### 1. **Vector Embedding Tools**\\n   - **Libraries**: Utilize deep learning frameworks like TensorFlow or PyTorch for generating word or sentence embeddings. Pre-trained models such as Word2Vec, FastText, or BERT can be used.\\n     - Example: Use Word2Vec for monolingual embeddings or BERT for multilingual embeddings.\\n\\n### 2. **Vector Search Engines**\\n   - **FAISS**: Implement for efficient similarity search with exact or approximate matches using binary search techniques.\\n   - **Milvus**: Suitable for large datasets and scalable applications, offering efficient vector searches.\\n\\n### 3. **API Development**\\n   - **Framework Selection**: Use FastAPI for a modern, high-performance API, or Flask if starting simpler.\\n   - **ASGI**: Utilize ASGI to enhance server efficiency compared to WSGI.\\n\\n### 4. **Database Integration**\\n   - **NoSQL Databases**: Use MongoDB or PostgreSQL with appropriate data types (e.g., JSONB for storing vectors).\\n   - **Data Structure**: Store documents with text content, embeddings, and metadata for efficient queries.\\n\\n### 5. **Query Processing and Search Logic**\\n   - **Embedding Generation**: For each query, generate embeddings using the chosen model.\\n   - **Search Functionality**: Implement logic to search through stored vectors, handle exact matches, similar embeddings, and ranking mechanisms.\\n\\n### 6. **User Interface and Experience**\\n   - **Input Handling**: Allow text input through forms or APIs for user queries.\\n   - **Output**: Return relevant results based on embedding similarity scores.\\n\\n### 7. **Efficiency Considerations**\\n   - **Preprocessing and Caching**: Optimize query processing with preprocessing steps and caching strategies to improve response times.\\n   - **Dockerization**: Containerize the application for easy deployment and scalability.\\n\\n### 8. **Testing and Validation**\\n   - **Testing Frameworks**: Use pytest or similar tools to validate embedding accuracy and search effectiveness.\\n   - **Sentence Embeddings**: Consider using pre-trained sentence embeddings for phrase-based searches.\\n\\n### 9. **Scalability and Resources**\\n   - **Cloud Services**: Utilize AWS, Google Cloud, or Azure for managed solutions that scale with your application needs.\\n   - **Monitoring**: Implement monitoring tools to track performance and handle high loads efficiently.\\n\\n### 10. **Documentation and User Experience**\\n   - **Comprehensive Documentation**: Provide clear guides for users on how to use the service effectively.\\n   - **Error Handling and Rate Limiting**: Implement measures to manage errors and prevent abuse.\\n\\nBy following these steps, you can build a robust web service that leverages vector embeddings for effective search, providing a seamless user experience while efficiently managing resources.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_deepseek(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781441f7-f87b-4e0a-80a2-3f238fa916cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QueryResponse(id='60aabd4c0a9a4323a4d613a068c36e33', embedding=None, sparse_embedding=None, metadata={'document': 'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!'}, document='Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!', score=0.6944532100424724),\n",
       " QueryResponse(id='908559de554048d4bdd6342e6dfc96f6', embedding=None, sparse_embedding=None, metadata={'document': 'SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.'}, document='SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.', score=0.6269391815273497),\n",
       " QueryResponse(id='1e2833b9c65a4101918c4b8fd80d311d', embedding=None, sparse_embedding=None, metadata={'document': 'FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.'}, document='FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.', score=0.5811869898549256)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = client.query(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    query_text=prompt,\n",
    "    limit=3,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196103ae-e2bd-44cf-b2af-9e84db39e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join(r.document for r in results)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78508e55-60c2-4363-b822-14c3e17d4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaprompt = f\"\"\"\n",
    "You are a software architect. \n",
    "Answer the following question using the provided context. \n",
    "If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "\n",
    "Question: {prompt.strip()}\n",
    "\n",
    "Context: \n",
    "{context.strip()}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Look at the full metaprompt\n",
    "print(metaprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73559a5f-f58a-410b-af75-52112adfd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_deepseek(metaprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7bdf24-9364-4291-a681-e5a4b2a6e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(question: str, n_points: int = 3) -> str:\n",
    "    results = client.query(\n",
    "        collection_name=\"knowledge-base\",\n",
    "        query_text=question,\n",
    "        limit=n_points,\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(r.document for r in results)\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a software architect. \n",
    "    Answer the following question using the provided context. \n",
    "    If you can't find the answer, do not pretend you know it, but only answer \"I don't know\".\n",
    "    \n",
    "    Question: {question.strip()}\n",
    "    \n",
    "    Context: \n",
    "    {context.strip()}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    return query_deepseek(metaprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2acf817e-66de-48ba-a917-5aef14cb83e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out what a stack for a web API might look like. Let me start by understanding the question. The user is asking about the structure of a web API's stack, given some context about FastAPI, NGINX, and Docker.\n",
      "\n",
      "From the context, FastAPI is described as a modern, high-performance web framework for building APIs using Python 3.7+. So that might be part of the application layer or backend.\n",
      "\n",
      "NGINX is mentioned as a high-performance HTTP server and reverse proxy, which typically sits in front of other applications. It's known for its performance, so maybe it's part of the infrastructure layer handling incoming requests.\n",
      "\n",
      "Docker is a containerization platform that helps build, share, and run applications without managing environments. So Docker would be related to the deployment or orchestration layer, allowing the application to be containerized and deployed efficiently.\n",
      "\n",
      "Putting this together, the stack for a web API might include FastAPI as the backend framework, NGINX as the reverse proxy and HTTP server, and Docker for containerization and deployment. That makes sense because each component serves a specific role in the overall architecture.\n",
      "\n",
      "I should structure it step by step: starting from the application (FastAPI), then the reverse proxy (NGINX), and then the containerization/Docker for deployment. This layered approach ensures that each part is handling its responsibilities efficiently.\n",
      "</think>\n",
      "\n",
      "The stack for a web API could consist of FastAPI as the backend framework, NGINX as the reverse proxy and HTTP server, and Docker for containerization and deployment.\n",
      "\n",
      "**Answer:**\n",
      "A typical web API stack might include:\n",
      "- **Application Layer**: FastAPI (for building APIs with Python).\n",
      "- **Reverse Proxy/HTTP Server**: NGINX (handling incoming requests and routing).\n",
      "- **Containerization/Orchestration**: Docker (deploying the application efficiently).\n",
      "\n",
      "This layered approach ensures efficient handling of both backend logic and infrastructure.\n"
     ]
    }
   ],
   "source": [
    "print(rag(\"What can the stack for a web api look like?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa05761-73c3-4c9a-8ffd-16643e406f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user is asking where the nearest grocery store is. Hmm, but looking at the context provided, it's all about software stuff: Qdrant, FastAPI, NGINX. None of that mentions anything related to grocery stores or locations. So I can't find any information here that would help answer their question. I should just say I don't know because there's no relevant data in the context. No point in making something up or guessing; better to be honest.\n",
      "</think>\n",
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "print(rag(\"Where is the nearest grocery store?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33d2515e-1485-42c2-bf16-e8da1060b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the tools required to build a web service that uses vector embeddings for search. Let me start by understanding what each part means.\n",
      "\n",
      "First, vector embeddings are like converting text or data into numerical vectors, right? These vectors can then be used to find similar items, which is useful for things like search or recommendations.\n",
      "\n",
      "Looking at the context provided, there are three tools mentioned: Qdrant, SentenceTransformers, and FastAPI. Let me break them down.\n",
      "\n",
      "Qdrant is described as a vector database and search engine. It acts as an API service, so it probably handles the actual storage and searching of these vectors. That makes sense because building a database from scratch would be time-consuming. So if I need to deploy a vector search service quickly, Qdrant might be the way to go.\n",
      "\n",
      "Next, SentenceTransformers is a Python framework for generating embeddings. It can handle text in over 100 languages and provides sentence embeddings. This tool is useful for tasks like semantic search or paraphrase mining because it generates vectors that represent the meaning of the text. So if I need to create these embeddings, SentenceTransformers would be necessary.\n",
      "\n",
      "Then there's FastAPI, which is a Python web framework known for its high performance. It uses standard type hints and is great for building APIs. Since the goal is to build a web service, having an efficient API layer is crucial. So combining FastAPI with the other tools might allow me to serve embeddings and perform searches via an API.\n",
      "\n",
      "Putting it all together: I think the process would involve using SentenceTransformers to generate the embeddings (maybe from text input), storing them in Qdrant's database, and then using FastAPI to create an endpoint that allows users to query this database. This way, clients can send a query, get it processed through FastAPI, which communicates with Qdrant to find the most relevant vectors based on cosine similarity or other similarity measures.\n",
      "\n",
      "Wait, but do I need anything else? Maybe some kind of middleware or orchestration tools? Or perhaps a reverse proxy like Gunicorn if I'm deploying multiple services. But the question specifically asks for tools to build the web service using vector embeddings, so maybe those aren't necessary unless specified.\n",
      "\n",
      "I should also consider deployment aspects. If Qdrant is already providing an API service, maybe it's hosted somewhere or I need to deploy it myself with Docker or Kubernetes. FastAPI would be deployed alongside it, perhaps on the same infrastructure.\n",
      "\n",
      "So in summary, the three main tools needed are:\n",
      "\n",
      "1. SentenceTransformers for generating embeddings from text.\n",
      "2. Qdrant for storing and searching these vectors.\n",
      "3. FastAPI to create the web interface and API endpoints that interact with both SentenceTransformers and Qdrant.\n",
      "\n",
      "I don't think there's a need for other tools unless there's more complexity, like data preprocessing or additional features beyond basic search. But based on the provided context, these three seem essential.\n",
      "</think>\n",
      "\n",
      "To build a web service using vector embeddings for search, you should use:\n",
      "\n",
      "1. **SentenceTransformers**: Generate text embeddings from input text.\n",
      "2. **Qdrant**: Store and search these embeddings efficiently.\n",
      "3. **FastAPI**: Build the API endpoints to handle requests and interact with Qdrant.\n",
      "\n",
      "These tools collectively allow you to create a service that processes text, converts it into vectors using SentenceTransformers, stores them in Qdrant for fast similarity searches, and serves results via an API built with FastAPI.\n"
     ]
    }
   ],
   "source": [
    "print(rag(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
