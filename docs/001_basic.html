<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Dense text embedding – python applied machine learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-49c8c4e9abc5c85f6ef827bc95f3ef76.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./001_basic.html">Dense text embedding</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">python applied machine learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_basic.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Dense text embedding</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_qdrant_client.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">002 Qdrant Client</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_fastembed_text_embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to generate Text Embeddings with FastEmbed</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_production_ready.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">004 Production Ready</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_splade.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to generate Sparse Vectors with SPLADE</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_generate_colbert_multivectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Generate ColBERT Multivectors with FastEmbed</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_reranking_fastembed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reranking with fastembed</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_smalldocling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OCR with SmallDocling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_long_context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">010 Long Context</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ar101_001_collaborative_filtering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advance Retrieval 101: Use Collaborative Filtering to Build a Movie Recommendation System</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ar101_002_multilingual_and_multimodal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Retrieval 101 Multilingual and Multimodal Search with LlamaIndex</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ar101_003_navigate_codebase.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Retrieval 101: Navigate Your Codebase with Semantic Search and Qdrant</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./e_001_data_ingestion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Essentials: Data Ingestion for Beginners</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./e_002_rag_deepseek.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Essentials: 5 Minute RAG with Qdrant and DeepSeek</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ss101_001_basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Search 101: Build your first Semantic Search Engine in 5 minutes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ss101_002_build_neural_search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Search 101: Build a Neural Search Service</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ss101_003_hybrid_search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Search 101: Build a Hybrid Search Service with FastEmbed and Qdrant</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ss101_004_measure_and_improve_retrieval_quality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semantic Search 101: Measure and Improve Retrieval Quality in Semantic Search</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sparse-text-embeddings" id="toc-sparse-text-embeddings" class="nav-link active" data-scroll-target="#sparse-text-embeddings"><span class="header-section-number">1.4</span> Sparse text embeddings</a></li>
  <li><a href="#late-interaction-models-aka-colbert" id="toc-late-interaction-models-aka-colbert" class="nav-link" data-scroll-target="#late-interaction-models-aka-colbert"><span class="header-section-number">2.4</span> Late interaction models (aka ColBERT)</a></li>
  <li><a href="#image-embeddings" id="toc-image-embeddings" class="nav-link" data-scroll-target="#image-embeddings"><span class="header-section-number">3.4</span> Image embeddings</a></li>
  <li><a href="#late-interaction-multimodal-models-colpali" id="toc-late-interaction-multimodal-models-colpali" class="nav-link" data-scroll-target="#late-interaction-multimodal-models-colpali"><span class="header-section-number">3.5</span> Late interaction multimodal models (ColPali)</a></li>
  <li><a href="#rerankers" id="toc-rerankers" class="nav-link" data-scroll-target="#rerankers"><span class="header-section-number">4.4</span> Rerankers</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Dense text embedding</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="b01e35c0-c3f4-4f30-808c-fd17513884cd" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext jupyter_ai</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config AiMagics.default_language_model <span class="op">=</span> <span class="st">"ollama:llama3.2"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The jupyter_ai extension is already loaded. To reload it, use:
  %reload_ext jupyter_ai</code></pre>
</div>
</div>
<div id="86c464a1-6e9f-4019-b720-d4cde326158e" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>ai</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">"Explain dense text embedding, keep it simple. Demonstrate some example. Give some real-world example"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="dense-text-embeddings" class="level1 cell-output cell-output-display cell-output-markdown" data-execution_count="24" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> <strong>Dense Text Embeddings</strong></h1>
<section id="what-is-a-dense-vector" class="level3" data-number="1.0.1">
<h3 data-number="1.0.1" class="anchored" data-anchor-id="what-is-a-dense-vector"><span class="header-section-number">1.0.1</span> What is a Dense Vector?</h3>
<p>A dense vector is a high-dimensional numerical representation of a piece of text.</p>
</section>
<section id="how-does-it-work" class="level3" data-number="1.0.2">
<h3 data-number="1.0.2" class="anchored" data-anchor-id="how-does-it-work"><span class="header-section-number">1.0.2</span> How Does it Work?</h3>
<p>Imagine you’re looking at a word and thinking of related words, like “apple” and “fruit”. A dense vector does something similar for an entire paragraph or sentence, but instead of words, it uses numerical values to represent the relationships between all the words in the text.</p>
</section>
<section id="example" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="example"><span class="header-section-number">1.1</span> ### Example</h2>
<p>Let’s say we have a piece of text: “The quick brown fox jumps over the lazy dog.”</p>
<p>We can represent this as two vectors:</p>
<ul>
<li>Vector A: <code>[0.1, 0.2, 0.3, ...]</code> (related to the word “quick”)</li>
<li>Vector B: <code>[0.4, 0.5, 0.6, ...]</code> (related to the word “brown”)</li>
</ul>
<p>Our dense vector would be a combination of these two vectors.</p>
</section>
<section id="real-world-examples" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="real-world-examples"><span class="header-section-number">1.2</span> ### Real-World Examples</h2>
<ol type="1">
<li><strong>Text Classification</strong>: Dense embeddings can be used as input features for text classification models, such as sentiment analysis or spam detection.</li>
<li><strong>Topic Modeling</strong>: Dense embeddings can help identify topics in large collections of text by capturing the underlying relationships between words.</li>
<li><strong>Information Retrieval</strong>: Dense embeddings can improve search results by representing documents and queries as dense vectors, allowing for more accurate matches.</li>
</ol>
</section>
<section id="code-example" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="code-example"><span class="header-section-number">1.3</span> ### Code Example</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to create a simple dense vector representation</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dense_vector(text):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the text into words</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> text.split()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary to store word vectors</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    word_vectors <span class="op">=</span> {}</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add each word to the dictionary</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, word <span class="kw">in</span> <span class="bu">enumerate</span>(words):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use a random numerical value as the vector for simplicity</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        word_vector <span class="op">=</span> np.random.rand(<span class="dv">768</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        word_vectors[word] <span class="op">=</span> word_vector</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine all word vectors into a single dense vector</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    dense_vector <span class="op">=</span> np.array([word_vectors[word] <span class="cf">for</span> word <span class="kw">in</span> words])</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dense_vector</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"The quick brown fox jumps over the lazy dog."</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>dense_vector <span class="op">=</span> create_dense_vector(text)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dense_vector.shape)  <span class="co"># Output: (1, 768)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, we use a simple dictionary to store word vectors and then combine them into a single dense vector.</p>
</section>
</section>
</div>
<div id="4e10325a-25ff-49d7-9039-0860c25d1255" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> TextEmbedding</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example list of documents</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>documents: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">=</span> [</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"This is built to be faster and lighter than other embedding libraries e.g. Transformers, Sentence-Transformers, etc."</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"fastembed is supported by and maintained by Qdrant."</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This will trigger the model download and initialization</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> TextEmbedding(model_name<span class="op">=</span><span class="st">"BAAI/bge-small-en-v1.5"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The model </span><span class="sc">{</span>embedding_model<span class="sc">.</span>model_name<span class="sc">}</span><span class="ss"> is ready to use."</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>embeddings_generator <span class="op">=</span> embedding_model.embed(documents)  <span class="co"># reminder this is a generator</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>embeddings_list <span class="op">=</span> <span class="bu">list</span>(embedding_model.embed(documents))</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># you can also convert the generator to a list, and that to a numpy array</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(embeddings_list[<span class="dv">0</span>])  <span class="co"># Vector of 384 dimensions</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The model BAAI/bge-small-en-v1.5 is ready to use.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>384</code></pre>
</div>
</div>
<div id="9e7c348d-0928-4d2d-806c-aff98be7b704" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> x: <span class="kw">not</span> x.startswith(<span class="st">"__"</span>), <span class="bu">dir</span>(embedding_model)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>['EMBEDDINGS_REGISTRY',
 'METADATA_FILE',
 '_get_model_description',
 '_list_supported_models',
 '_local_files_only',
 'add_custom_model',
 'cache_dir',
 'decompress_to_cache',
 'download_file_from_gcs',
 'download_files_from_huggingface',
 'download_model',
 'embed',
 'list_supported_models',
 'model',
 'model_name',
 'passage_embed',
 'query_embed',
 'retrieve_model_gcs',
 'threads']</code></pre>
</div>
</div>
<div id="41b917ad-538a-416f-a7e6-a2e6227409b6" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>embedding_model.model_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>'BAAI/bge-small-en-v1.5'</code></pre>
</div>
</div>
<section id="sparse-text-embeddings" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sparse-text-embeddings"><span class="header-section-number">1.4</span> Sparse text embeddings</h2>
<div id="10cc98bd-4237-49d4-97f7-598ef598286d" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>ai</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">"Explain sparse text embedding, keep it simple. Demonstrate some example. Give some real-world example"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="sparse-text-embeddings-1" class="level1 cell-output cell-output-display cell-output-markdown" data-execution_count="25" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> <strong>Sparse Text Embeddings</strong></h1>
<section id="what-is-a-sparse-vector" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="what-is-a-sparse-vector"><span class="header-section-number">2.0.1</span> What is a Sparse Vector?</h3>
<p>A sparse vector is a numerical representation of a piece of text where most values are 0.</p>
</section>
<section id="how-does-it-work-1" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="how-does-it-work-1"><span class="header-section-number">2.0.2</span> How Does it Work?</h3>
<p>Imagine you’re looking at a word and thinking of related words, like “apple” and “fruit”. A sparse vector would have a few non-zero values representing the relationships between these words, but most values would be 0 (representing unrelated words).</p>
</section>
<section id="example-1" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="example-1"><span class="header-section-number">2.1</span> ### Example</h2>
<p>Let’s say we have a piece of text: “The quick brown fox jumps over the lazy dog.”</p>
<p>We can represent this as two sparse vectors:</p>
<ul>
<li>Vector A: <code>[0.1, 0, 0, ...]</code> (related to the word “quick”)</li>
<li>Vector B: <code>[0, 0.4, 0, ...]</code> (related to the word “brown”)</li>
</ul>
<p>Our sparse vector would have only non-zero values representing the relationships between these two words.</p>
</section>
<section id="real-world-examples-1" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="real-world-examples-1"><span class="header-section-number">2.2</span> ### Real-World Examples</h2>
<ol type="1">
<li><strong>Text Classification</strong>: Sparse embeddings can be used as input features for text classification models, such as sentiment analysis or spam detection.</li>
<li><strong>Topic Modeling</strong>: Sparse embeddings can help identify topics in large collections of text by capturing the underlying relationships between words.</li>
<li><strong>Word Embeddings</strong>: Sparse embeddings can be used to represent individual words, like Word2Vec or GloVe.</li>
</ol>
</section>
<section id="code-example-1" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="code-example-1"><span class="header-section-number">2.3</span> ### Code Example</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to create a simple sparse vector representation</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_sparse_vector(text):</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the text into words</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> text.split()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary to store word vectors</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    word_vectors <span class="op">=</span> {}</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add each word to the dictionary</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, word <span class="kw">in</span> <span class="bu">enumerate</span>(words):</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use a random numerical value as the vector for simplicity</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        word_vector <span class="op">=</span> np.random.rand(<span class="dv">768</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        word_vector[i] <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># Set the correct value</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        word_vectors[word] <span class="op">=</span> word_vector</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine all word vectors into a single sparse vector</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    sparse_vector <span class="op">=</span> np.array([word_vectors[word][i] <span class="cf">for</span> i, word <span class="kw">in</span> <span class="bu">enumerate</span>(words)])</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sparse_vector</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"The quick brown fox jumps over the lazy dog."</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>sparse_vector <span class="op">=</span> create_sparse_vector(text)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sparse_vector.shape)  <span class="co"># Output: (1, 768)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, we use a simple dictionary to store word vectors and then combine them into a single sparse vector. The <code>i</code>-th value in each word vector is set to 1.0 to represent the correct relationship between words.</p>
</section>
</section>
</div>
<div id="8df1694b-f843-47de-9812-62f20c58d684" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> SparseTextEmbedding</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SparseTextEmbedding(model_name<span class="op">=</span><span class="st">"prithivida/Splade_PP_en_v1"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> <span class="bu">list</span>(model.embed(documents))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>embeddings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>[SparseEmbedding(values=array([0.46793732, 0.34634435, 0.82014424, 0.45307532, 0.98732066,
        0.80176616, 0.2087955 , 0.07078066, 0.15851103, 0.07413071,
        0.34253079, 0.88557774, 0.13234277, 0.23698376, 0.07734038,
        0.20083414, 1.3942709 , 0.57856292, 0.75639009, 0.12872015,
        0.12940496, 1.21411681, 0.3960413 , 0.38100156, 0.85480541,
        0.23132324, 0.61133695, 0.34899744, 0.15025412, 0.1130122 ,
        0.15241024, 0.36152679, 0.13700481, 0.7303589 , 1.39194822,
        0.04954698, 0.49473077, 0.30635571, 0.06034151, 1.13118982,
        0.01341425, 0.02633621, 0.10710741, 1.03937888, 0.05903498,
        0.33036089, 0.0278459 , 0.04743589, 1.68689609, 0.62101287,
        1.86998868, 0.71478194, 0.08071101, 1.26968515, 0.05093801,
        0.09553559, 1.57417607, 0.18500556, 0.0425379 , 0.24046306,
        1.08656394, 0.72864759, 0.1876028 , 0.85070795, 0.16575399,
        0.23869337, 0.52304912, 0.90775394, 0.02330356, 0.12363458,
        0.37557927, 1.93465626, 0.5360083 , 0.08284581, 0.39607322,
        0.13179989]), indices=array([ 2022,  2060,  2084,  2138,  2328,  2422,  2488,  2544,  2640,
         2653,  2742,  2793,  2828,  2881,  3033,  3074,  3075,  3082,
         3177,  3274,  3430,  3435,  3642,  3800,  3857,  3989,  4007,
         4127,  4248,  4289,  4294,  4385,  4406,  4489,  4667,  4773,
         5056,  5080,  5371,  5514,  5672,  6028,  6082,  6251,  6254,
         6994,  7705,  7831,  7861,  7915,  8270,  8860,  8875,  8957,
         9121,  9262,  9442, 10472, 10763, 10899, 10938, 11746, 11892,
        11907, 12430, 12692, 13507, 13850, 15106, 16473, 19059, 19081,
        21331, 23561, 23924, 27014])),
 SparseEmbedding(values=array([0.08703687, 2.10778594, 0.01475082, 0.16455774, 0.09053489,
        0.04780621, 0.89654833, 1.0727092 , 0.05152059, 0.19544077,
        1.18726742, 0.09147657, 0.53395849, 0.36316222, 0.05458989,
        1.05834925, 0.21000545, 0.2174563 , 0.4657135 , 0.16001791,
        2.58359981, 1.51888502, 0.42704242, 0.85715246, 0.22741754,
        0.1889631 , 0.04392261, 0.03791322, 0.5099448 , 1.10458422,
        0.20403962, 0.97265482, 0.0194856 , 0.86876655, 0.10075891,
        2.00031805, 0.24204996, 0.07565179, 0.52923071, 0.48402771,
        0.19994174, 1.99733865, 0.42608464, 0.18558736, 0.15080665,
        0.13985491, 0.54798013, 0.16576864, 0.19238883, 0.57402122,
        2.63415504]), indices=array([ 1010,  1053,  2003,  2009,  2025,  2040,  2102,  2194,  2284,
         2291,  2490,  2497,  2544,  2562,  2572,  2793,  2897,  2974,
         3079,  3274,  3435,  3569,  3954,  4007,  4289,  4316,  4322,
         4434,  5080,  5224,  5371,  5441,  5527,  6032,  6153,  6633,
         7506,  7621,  7751,  7861,  8241,  8270,  8498,  9319,  9722,
        10472, 12494, 13666, 16350, 20486, 24914]))]</code></pre>
</div>
</div>
</section>
<section id="late-interaction-models-aka-colbert" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="late-interaction-models-aka-colbert"><span class="header-section-number">2.4</span> Late interaction models (aka ColBERT)</h2>
<div id="65eea562-bee1-4037-81dc-f6d840ddd34f" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>ai ollama:llama3<span class="fl">.2</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">"Explain late interaction models (aka ColBERT), keep it simple. Demonstrate some example. Give some real-world example"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="late-interaction-models-colbert" class="level1 cell-output cell-output-display cell-output-markdown" data-execution_count="26" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> <strong>Late Interaction Models (ColBERT)</strong></h1>
<section id="what-is-late-interaction" class="level3" data-number="3.0.1">
<h3 data-number="3.0.1" class="anchored" data-anchor-id="what-is-late-interaction"><span class="header-section-number">3.0.1</span> What is Late Interaction?</h3>
<p>Late interaction models are a type of search model that improves the performance of early interaction methods, such as BM25.</p>
</section>
<section id="how-does-it-work-2" class="level3" data-number="3.0.2">
<h3 data-number="3.0.2" class="anchored" data-anchor-id="how-does-it-work-2"><span class="header-section-number">3.0.2</span> How Does it Work?</h3>
<p>Imagine you’re searching for documents related to a query. Early interaction methods like BM25 use features extracted from the query and the document to rank them. Late interaction models refine these rankings by using additional information, such as the entire document or other relevant documents.</p>
</section>
<section id="example-2" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="example-2"><span class="header-section-number">3.1</span> ### Example</h2>
<p>Let’s say we have a search model that uses BM25 to rank documents for a query “computer science”. The top 5 ranked documents are:</p>
<ol type="1">
<li><strong>A paper on computer vision</strong></li>
<li><strong>A blog post on machine learning</strong></li>
<li><strong>A Wikipedia page on artificial intelligence</strong></li>
<li><strong>A news article on data science</strong></li>
<li><strong>A book review on software engineering</strong></li>
</ol>
<p>Late interaction models like ColBERT can improve these rankings by considering additional features, such as:</p>
<ul>
<li>The entire document text</li>
<li>Other relevant documents in the corpus</li>
</ul>
</section>
<section id="real-world-examples-2" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="real-world-examples-2"><span class="header-section-number">3.2</span> ### Real-World Examples</h2>
<ol type="1">
<li><strong>E-commerce Search</strong>: Late interaction models can improve search results for e-commerce platforms by incorporating product descriptions, reviews, and other relevant information.</li>
<li><strong>Knowledge Graph Search</strong>: Late interaction models can be used to search knowledge graphs, which are databases of entities and their relationships.</li>
<li><strong>Recommendation Systems</strong>: Late interaction models can be used to recommend items based on user behavior and preferences.</li>
</ol>
</section>
<section id="code-example-2" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="code-example-2"><span class="header-section-number">3.3</span> ### Code Example</h2>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to create a ColBERT model</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_colbert_model(query, documents):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract features from the query and documents using BM25</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    bm25_features <span class="op">=</span> bm25_query_and_document(query, documents)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add additional features using late interaction</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    colbert_features <span class="op">=</span> add_late_interaction(bm25_features, query, documents)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> colbert_features</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to calculate BM25 features</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bm25_query_and_document(query, documents):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement BM25 calculation here</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to add late interaction features</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_late_interaction(features, query, documents):</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement late interaction calculation here</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, we define a simple ColBERT model that uses BM25 as an early interaction method and adds additional features using late interaction. The <code>bm25_query_and_document</code> function calculates BM25 features, and the <code>add_late_interaction</code> function calculates late interaction features.</p>
</section>
</section>
</div>
<div id="873c1397-ad6b-4562-9070-9b552c430411" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> LateInteractionTextEmbedding</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LateInteractionTextEmbedding(model_name<span class="op">=</span><span class="st">"colbert-ir/colbertv2.0"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> <span class="bu">list</span>(model.embed(documents))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>embeddings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>[array([[-0.1351824 ,  0.12230334,  0.1269857 , ...,  0.17307524,
          0.11274203,  0.02880633],
        [-0.17495233,  0.08767531,  0.11352374, ...,  0.12433604,
          0.15752925,  0.08118125],
        [-0.10130584,  0.09613474,  0.13923067, ...,  0.12898032,
          0.16839182,  0.09858395],
        ...,
        [-0.10270972,  0.01041561,  0.04440113, ...,  0.0550529 ,
          0.08930317,  0.09720251],
        [-0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [-0.15476122,  0.06961455,  0.10665789, ...,  0.15388842,
          0.09050205,  0.00516431]], shape=(29, 128), dtype=float32),
 array([[ 0.12170535,  0.07871944,  0.12508287, ...,  0.08450251,
          0.01834184, -0.01686618],
        [-0.02659732, -0.12131035,  0.14012505, ..., -0.01885814,
          0.01064609, -0.05982119],
        [-0.03633325, -0.14667122,  0.14062028, ..., -0.052545  ,
          0.00967532, -0.08844125],
        ...,
        [-0.        ,  0.        ,  0.        , ..., -0.        ,
         -0.        ,  0.        ],
        [-0.        , -0.        ,  0.        , ..., -0.        ,
         -0.        , -0.        ],
        [-0.        , -0.        ,  0.        , ..., -0.        ,
          0.        , -0.        ]], shape=(29, 128), dtype=float32)]</code></pre>
</div>
</div>
</section>
<section id="image-embeddings" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="image-embeddings"><span class="header-section-number">3.4</span> Image embeddings</h2>
<div id="01c095a4-2e2e-4353-9fce-c4b3e4bd482a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> ImageEmbedding</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> [<span class="st">"images/cat1.jpeg"</span>, <span class="st">"images/cat2.jpeg"</span>, <span class="st">"images/dog1.webp"</span>]</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ImageEmbedding(model_name<span class="op">=</span><span class="st">"Qdrant/clip-ViT-B-32-vision"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> <span class="bu">list</span>(model.embed(images))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2983017a-6f17-47c2-85de-b61f18d5b787" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client.local.distances <span class="im">import</span> cosine_similarity</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="43167e4c-beb7-4a5d-a50f-3b196a8efca0" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>cosine_similarity(np.array(embeddings), np.array(embeddings))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>array([[1.0000001 , 0.83723867, 0.61121917],
       [0.83723867, 1.0000002 , 0.7055948 ],
       [0.61121917, 0.7055948 , 1.0000001 ]], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="late-interaction-multimodal-models-colpali" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="late-interaction-multimodal-models-colpali"><span class="header-section-number">3.5</span> Late interaction multimodal models (ColPali)</h2>
<div id="6c384932-9e4c-4e95-b8ae-403ca6b80ade" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>ai</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">"Explain late interaction multimodal models (aka ColPali), keep it simple. Demonstrate some example. Give some real-world example"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="late-interaction-multimodal-models-colpali-1" class="level1 cell-output cell-output-display cell-output-markdown" data-execution_count="27" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> <strong>Late Interaction Multimodal Models (ColPali)</strong></h1>
<section id="what-is-late-interaction-1" class="level3" data-number="4.0.1">
<h3 data-number="4.0.1" class="anchored" data-anchor-id="what-is-late-interaction-1"><span class="header-section-number">4.0.1</span> What is Late Interaction?</h3>
<p>Late interaction models are a type of search model that improves the performance of early interaction methods, such as BM25.</p>
</section>
<section id="how-does-it-work-3" class="level3" data-number="4.0.2">
<h3 data-number="4.0.2" class="anchored" data-anchor-id="how-does-it-work-3"><span class="header-section-number">4.0.2</span> How Does it Work?</h3>
<p>Imagine you’re searching for documents related to a query. Early interaction methods like BM25 use features extracted from the query and the document to rank them. Late interaction models refine these rankings by using additional information, such as the entire document or other relevant documents.</p>
</section>
<section id="multimodal-models" class="level3" data-number="4.0.3">
<h3 data-number="4.0.3" class="anchored" data-anchor-id="multimodal-models"><span class="header-section-number">4.0.3</span> Multimodal Models</h3>
<p>Multimodal models extend late interaction models to incorporate multiple input modalities, such as text, images, audio, and video.</p>
</section>
<section id="example-3" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="example-3"><span class="header-section-number">4.1</span> ### Example</h2>
<p>Let’s say we have a search model that uses ColPali to rank documents for a query “computer science”. The input modalities are:</p>
<ul>
<li><strong>Text</strong>: A passage of text related to the query.</li>
<li><strong>Image</strong>: An image related to the query (e.g.&nbsp;a diagram of a computer chip).</li>
<li><strong>Audio</strong>: An audio file related to the query (e.g.&nbsp;a lecture on machine learning).</li>
</ul>
<p>The ColPali model extracts features from each modality and combines them using late interaction. The final ranking is based on the weighted sum of these features.</p>
</section>
<section id="real-world-examples-3" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="real-world-examples-3"><span class="header-section-number">4.2</span> ### Real-World Examples</h2>
<ol type="1">
<li><strong>Image Search with Text Description</strong>: Late interaction multimodal models can be used to search images based on a text description.</li>
<li><strong>Speech Recognition with Visual Feedback</strong>: ColPali can be used in speech recognition systems that incorporate visual feedback, such as displaying the recognized text in real-time.</li>
<li><strong>Multimodal Question Answering</strong>: Late interaction multimodal models can be used to answer questions that require information from multiple input modalities (e.g.&nbsp;text, images, audio).</li>
</ol>
</section>
<section id="code-example-3" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="code-example-3"><span class="header-section-number">4.3</span> ### Code Example</h2>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to create a ColPali model</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_colpali_model(query, text, image, audio):</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract features from each modality using late interaction</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    text_features <span class="op">=</span> extract_features(text, query)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    image_features <span class="op">=</span> extract_features(image, query)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    audio_features <span class="op">=</span> extract_features(audio, query)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine features using weighted sum</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    combined_features <span class="op">=</span> combine_features(text_features, image_features, audio_features)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> combined_features</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to extract features from text using late interaction</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_features(text, query):</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement late interaction calculation here</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to combine features using weighted sum</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> combine_features(text_features, image_features, audio_features):</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement weighted sum calculation here</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, we define a simple ColPali model that uses late interaction to extract features from each modality and combines them using a weighted sum. The <code>extract_features</code> function calculates features for each modality, and the <code>combine_features</code> function calculates the final combined features.</p>
</section>
</section>
</div>
<div id="db2e7251-921a-4f24-8fbe-41790107d592" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> LateInteractionMultimodalEmbedding</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>doc_images <span class="op">=</span> [</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"images/wiki_computer_science.png"</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"images/wiki_technology.png"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"images/wiki_space.png"</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"what is tech"</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LateInteractionMultimodalEmbedding(model_name<span class="op">=</span><span class="st">"Qdrant/colpali-v1.3-fp16"</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>doc_images_embeddings <span class="op">=</span> <span class="bu">list</span>(model.embed_image(doc_images))</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>query_embedding <span class="op">=</span> model.embed_text(query)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7e797b37-0af9-409b-af8c-952f715483e1" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client <span class="im">import</span> models</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client.local.multi_distances <span class="im">import</span> calculate_multi_distance</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># How to calculate distance?</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># from qdrant_client.local.sparse_distances import calculate_distance_sparse</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate_multi_distance(</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     query_embedding,</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     doc_images_embeddings,</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     # distance_type=models.MultiVectorComparator.MAX_SIM,</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">#     distance_type=models.Distance.DOT,</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="rerankers" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="rerankers"><span class="header-section-number">4.4</span> Rerankers</h2>
<div id="318803d6-cb06-4c9b-abcd-614fc16d5a9b" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed.rerank.cross_encoder <span class="im">import</span> TextCrossEncoder</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"Who is maintaining Qdrant?"</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>documents: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">=</span> [</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"This is built to be faster and lighter than other embedding libraries e.g. Transformers, Sentence-Transformers, etc."</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"fastembed is supported by and maintained by Qdrant."</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> TextCrossEncoder(model_name<span class="op">=</span><span class="st">"Xenova/ms-marco-MiniLM-L-6-v2"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> <span class="bu">list</span>(encoder.rerank(query, documents))</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>scores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>